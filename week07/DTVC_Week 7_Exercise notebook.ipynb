{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: From linear to logistic regression...\n",
    "\n",
    "We use again the `chimera_data.csv` from earlier lectures. We will try to predict employee exit, using only some of the key columns in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"chimera_data.csv\")\n",
    "df = df[[\"boss_survey\",\"salary\",\"exit\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df.exit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"boss_survey\",y=\"salary\",hue=\"exit\",data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simplify this further, by looking only at the `boss_survey` result as an independent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"boss_survey\",y=\"exit\",data=df)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, of course, run a linear regression on this data. We will use scikit here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[[\"boss_survey\"]]\n",
    "Y=df[[\"exit\"]]\n",
    "\n",
    "lm = LinearRegression().fit(X, Y) # Fit a linear regression with vector Y as dependent and matrix X as independent\n",
    "\n",
    "print(\"Intercept = \",lm.intercept_) # Print the resultant model intercept \n",
    "print(\"Model coefficients = \", lm.coef_) # Print the resultant model coefficients (in order of variables in X)\n",
    "print(\"R^2 =\",lm.score(X,Y)) # Print the resultant model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the result using scikit's `predict` function together with `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=lm.predict(X)\n",
    "sns.relplot(x=\"boss_survey\",y=\"exit\",data=df)\n",
    "plt.plot(X,Y_pred,color=\"red\")\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are rather problematic. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate logistic regression\n",
    "\n",
    "We use scikit-learn here to do Logistic Regression. The code looks very similar to Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[[\"boss_survey\"]]\n",
    "y=df[\"exit\"]\n",
    "\n",
    "logm = LogisticRegression().fit(X, y) # Fit a logistic regression with vector Y as dependent and matrix X as independent\n",
    "\n",
    "print(\"Intercept = \",logm.intercept_) # Print the resultant model intercept \n",
    "print(\"Model coefficients = \", logm.coef_) # Print the resultant model coefficients (in order of variables in X)\n",
    "print(\"R^2 =\",logm.score(X,y)) # Print the resultant model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the predictions, we proceed as with linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred=logm.predict(X)\n",
    "sns.histplot(labels_pred,stat='percent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction above is based on an arbitrary threshold around the probability of leaving. We can, instead, look at that probability. For this, we use `.predict_proba(X)`. Be aware that this returns both sides (the probability of not leaving and the probability of leaving) for each employee:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_pred=logm.predict_proba(X)\n",
    "print(probs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the probability of leaving against the actual choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot, y_plot = zip(*sorted(zip(X.values, probs_pred[:,1])))\n",
    "sns.relplot(x=\"boss_survey\",y=\"exit\",data=df)\n",
    "plt.plot(X_plot, y_plot,color=\"red\")\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate logistic regression\n",
    "\n",
    "Of course, we can use more than one explanatory variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[\"exit\"] #creating the dependent variable\n",
    "X=df.drop(columns=[\"exit\"]) #dropping the dependent variable to get a matrix of independent features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the logit model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm = LogisticRegression().fit(X, y) # Fit a logistic regression with vector Y as dependent and matrix X as independent\n",
    "\n",
    "print(\"Intercept = \",logm.intercept_) # Print the resultant model intercept \n",
    "print(\"Model coefficients = \", logm.coef_) # Print the resultant model coefficients (in order of variables in X)\n",
    "print(\"R^2 =\",logm.score(X,y)) # Print the resultant model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Setting the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have just predicted the model on the same data as the data on which we trained it. Of course, this is not ideal. Here, we will be using a train and a validation dataset to find the best threshold, then use this threshold to check how good our model is on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"exit\"] #creating the dependent variable\n",
    "X = df.drop(columns=[\"exit\"]) #dropping the dependent variable to get a matrix of independent features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into train (50%), test (25%) and validation (25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, otherX, trainY, otherY = train_test_split(X, Y, test_size=0.5,random_state = 726)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, validationX, testY, validationY = train_test_split(otherX, otherY, test_size=0.5,random_state = 1592)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(validationX.shape)\n",
    "print(validationY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model to the dataset using scikit learn, **only on the training data**:\n",
    "\n",
    "Note: `.values.ravel()` will turn the dataframe column-vector `trainY` into a 1-dimensional array and avoid warnings. It's not strictly necessary with the current version of Python, but it may avoid issues in future versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm = LogisticRegression()\n",
    "logm.fit(trainX, trainY.values.ravel()) # Fit a logistic regression with vector Y as dependent and matrix X as independent\n",
    "print(logm.intercept_)\n",
    "print(logm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we get prediction probabilities (this time on the validation dataset). However, we only care about one side (the probability of having \"1\", that is, of leaving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm.predict_proba(validationX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_probs=logm.predict_proba(validationX)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now display the ROC curve. For this, we use `roc_curve` from `sklearn.metrics` (the documentation is [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)). The function returns three lists, all indexed in the same way. In the first list, we can find the false positive rates, in the second list we find the true positive rates, and in the third list, we find the corresponding threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "fpr, tpr, thresholds = metrics.roc_curve(validationY,Y_probs)\n",
    "pyplot.plot(fpr, tpr, linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can stake out the different points on the graph manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The threshold at index 10 is \" + str(thresholds[10]))\n",
    "print(\"The false positive rate at this threshold is \" + str(fpr[10]))\n",
    "print(\"The true positive rate at this threshold is \" + str(tpr[10])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The threshold at index 200 is \" + str(thresholds[200]))\n",
    "print(\"The false positive rate at this threshold is \" + str(fpr[200]))\n",
    "print(\"The true positive rate at this threshold is \" + str(tpr[200])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The threshold at index 800 is \" + str(thresholds[800]))\n",
    "print(\"The false positive rate at this threshold is \" + str(fpr[800]))\n",
    "print(\"The true positive rate at this threshold is \" + str(tpr[800])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC summarizes the quality of our model by measuring (roughly) how close we can get to a perfect model. In particular, it gives an idea of how far to the top-left we can get in our ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(validationY,Y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to choose a threshold (note, the default chosen in making predictions by sklean is 0.5). A natural threshold to choose is 0.1355 (why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_threshold = np.min(thresholds[thresholds > 0.1355])\n",
    "print(chosen_threshold)\n",
    "threshold_idx = np.where(thresholds == chosen_threshold)[0][0]\n",
    "print(threshold_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FPR and TPR at this threshold are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"At threshold  \" + str(thresholds[threshold_idx]))\n",
    "print(\"the false positive rate is \" + str(fpr[threshold_idx]))\n",
    "print(\"and the true positive rate is \" + str(tpr[threshold_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a choice of thresholds, we can now make predictions (on the validation set) and display the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.where(Y_probs > chosen_threshold, 1, 0)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(validationY,Y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now verify the false and true positive rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-TN/(FP+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will discuss other methods for choosing thresholds in the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Retraining the final model with training+validation, then testing it (time permitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_final=pd.concat([trainX, validationX])\n",
    "trainY_final=pd.concat([trainY, validationY])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train our model on `trainX_final` and `trainY_final` with treshold `0.1355` using scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm = LogisticRegression().fit(trainX_final, trainY_final.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_probs=logm.predict_proba(validationX)[:,1]\n",
    "threshold = 0.1355\n",
    "Y_test_pred=np.where(Y_test_probs > threshold, 1, 0) #predict the classes for test data based on the threshold found via the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(testY,Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Using CART decision trees for classification (time permitting - we will look at this in the tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ways to perform classification, such as decision trees. While we won't talk a lot about the underlying theory (you will cover this in your machine learning class), they can be quite the powerful tool for classification (and, actually, also for prediction).\n",
    "\n",
    "Compared to logistic regression, decision trees don't require any structural assumptions (remember, under logistic regression, we assume an exponential of a linear function). However, greater flexibility comes at a cost: there are a bunch more options to choose from when using those. For our purposes, we will concentrate on the `max_leaf_nodes`, which is usually the option with the biggest impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import graphviz as gp\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage in Python is quite intuitive - we only need to replace `LogisticRegression` with `DecisionTreeClassifier` (and define the `max_leaf_nodes`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_DT = DecisionTreeClassifier(max_leaf_nodes = 4)\n",
    "classifier_DT.fit(trainX, trainY.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the major advantages of decision trees is that they are quite intuitive. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(classifier_DT, feature_names = trainX.columns, filled = True, rounded = True, class_names=[\"No exit\",\"Exit\"])\n",
    "graph = gp.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage is exactly as with the logistic regression. For example, we can get the probability of exit on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_probs=classifier_DT.predict_proba(validationX)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the ROC curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "fpr, tpr, thresholds = metrics.roc_curve(validationY,Y_probs)\n",
    "pyplot.plot(fpr, tpr, linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can find the AUC to measure the quality of the model. We could, for example, vary `max_leaf_nodes` to get a higher AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(validationY,Y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are even more advanced classifiers, such as\n",
    "```\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "```\n",
    "They bring in better predictive power at the cost of higher parameter-setting complexity. But the usage is pretty much the same as for logistic regression and CART, so feel free to try it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: FP and FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give everyday life examples where it would be preferable to (i) have false positives rather than false negatives, or (ii) have false negatives rather than false positives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtvc_env",
   "language": "python",
   "name": "dtvc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
