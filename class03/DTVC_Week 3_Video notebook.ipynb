{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvDB54ejVtY8"
   },
   "source": [
    "# Descriptive Analytics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LtSIaVEz0yD"
   },
   "source": [
    "You know the drill by now - never reinvent the wheel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oK9uzw_ZVtY9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tXHvmToa1uDX"
   },
   "source": [
    "# Part 1: Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using Google Colab, we need to upload our data (chimera_data.csv) to make it useable. Luckily, we can simply create a \"choose file\" button and then select and upload our file.\n",
    "```\n",
    "import os.path\n",
    "from google.colab import files\n",
    "if not os.path.exists(\"chimera_data.csv\"):\n",
    "    uploaded = files.upload()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have uploaded our file, we need to set a path to it and acces it with `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"chimera_data.csv\"\n",
    "df = pd.read_csv(path, sep = \",\") # create a pandas data frame to store data, set the type of separator used in your CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a sneak peak at what we imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin_support</th>\n",
       "      <th>age</th>\n",
       "      <th>boss_survey</th>\n",
       "      <th>boss_tenure</th>\n",
       "      <th>city_size</th>\n",
       "      <th>clock_in</th>\n",
       "      <th>core</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>half_day_leaves</th>\n",
       "      <th>...</th>\n",
       "      <th>remote</th>\n",
       "      <th>salary</th>\n",
       "      <th>subordinates</th>\n",
       "      <th>team_size</th>\n",
       "      <th>tenure</th>\n",
       "      <th>tenure_unit</th>\n",
       "      <th>training</th>\n",
       "      <th>variable_pay</th>\n",
       "      <th>years_since_promotion</th>\n",
       "      <th>exit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>0.655444</td>\n",
       "      <td>3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>53.894035</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.533455</td>\n",
       "      <td>4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35.606964</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.486568</td>\n",
       "      <td>5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27.400360</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.477364</td>\n",
       "      <td>4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>36.138199</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0.603230</td>\n",
       "      <td>4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42.778580</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   admin_support  age  boss_survey  boss_tenure  city_size  clock_in  core  \\\n",
       "0              2   35     0.655444            3        6.1         1     1   \n",
       "1              0   33     0.533455            4        9.4         0     1   \n",
       "2              0   32     0.486568            5        2.2         0     1   \n",
       "3              0   40     0.477364            4        4.3         0     1   \n",
       "4              2   47     0.603230            4        2.2         0     1   \n",
       "\n",
       "   education  gender  half_day_leaves  ...  remote     salary  subordinates  \\\n",
       "0          2       1                4  ...       0  53.894035             0   \n",
       "1          2       0                5  ...       0  35.606964             0   \n",
       "2          1       0                4  ...       0  27.400360             0   \n",
       "3          3       0                4  ...       0  36.138199             0   \n",
       "4          1       1                5  ...       0  42.778580             1   \n",
       "\n",
       "   team_size  tenure  tenure_unit  training  variable_pay  \\\n",
       "0          9       3            3         3            11   \n",
       "1          6       1            1         3             1   \n",
       "2         10       2            2         3             1   \n",
       "3          8       1            1         3             0   \n",
       "4          9       1            1         2            11   \n",
       "\n",
       "   years_since_promotion  exit  \n",
       "0                      3     0  \n",
       "1                      3     0  \n",
       "2                      4     0  \n",
       "3                      4     0  \n",
       "4                      4     1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnXno7Np6Xap"
   },
   "source": [
    "We can also get a summary of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZCjXWui6OuF"
   },
   "outputs": [],
   "source": [
    "summary_stats = df.describe()\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you already know, visualization is an extremely powerful tool within the descriptive analytics arsenal. Usually, you want to check the histograms of some of the key variables to get a feel for the data and to discover any issues (more on this part in class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"boss_survey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also count the number of empty values per column (note that there is none here - the dataset is already cleaned):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwlYxUYT6dhO"
   },
   "source": [
    "# Part 2: Bivariate tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 t-tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgF34E8u6m4H"
   },
   "source": [
    "Let's see whether we can find any initial trends in the data. For example, are women more likely to exit the firm? We will use [t-tests](https://towardsdatascience.com/the-statistical-analysis-t-test-explained-for-beginners-and-experts-fd0e358bbb62) to analyze the difference in means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNrrqXEjVtZE"
   },
   "outputs": [],
   "source": [
    "ttest = sm.stats.ttest_ind(df[df.gender==0].exit,df[df.gender==1].exit)\n",
    "\n",
    "tstat = ttest[0] \n",
    "pvalue = ttest[1] \n",
    "\n",
    "print('the tstat for gender differences in exit is =', tstat)\n",
    "print('the pvalue is =', pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1In7vus57iB8"
   },
   "source": [
    "The data indicates that women are, on average, more likely to quit. However, the finding is not very [significant from a statistical perspective](https://hbr.org/2016/02/a-refresher-on-statistical-significance). Also, don't forget that we are just taking a look at two variables, ignoring a lot of other information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7S_fHNj7GCi"
   },
   "source": [
    "Maybe exiters are paid less?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnKc92Hs7HoR"
   },
   "outputs": [],
   "source": [
    "ttest = sm.stats.ttest_ind(df[df.exit==1].salary,df[df.exit==0].salary)\n",
    "\n",
    "tstat = ttest[0]\n",
    "pvalue =  ttest[1]\n",
    "\n",
    "print('the tstat for salary differences in exit is =', tstat)\n",
    "print('the pvalue is =', pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZBYmrEX762K"
   },
   "source": [
    "There indeed is a difference in average salary between those that exit and those that don't. This time, statistically speaking, we can be more sure of this difference. But again, don't forget that we are looking at only two variables right now, i.e. we are assuming all else is equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZdYLdUn7Itu"
   },
   "source": [
    "**Exercise:** can you write a test to check if exiters (1) have higher or lower job satisfaction than stayers?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETBNz64Y_T5L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8OtDlqc8Paw"
   },
   "source": [
    "## 2.2 Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZAJari88aRx"
   },
   "source": [
    "We create a new pandas data frame to store the [correlation](https://https://en.wikipedia.org/wiki/Correlation_and_dependence) information, which we can display using `seaborn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr(method='pearson', min_periods=1)\n",
    "sns.heatmap(correlation_matrix, vmax=0.15,vmin=-0.15,  # vmax and vmin define the upper and lower boundaries of the colormap respectively\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can improve the display. One thing to note, in particular, is that a correlation matrix is always symmetric - we do not need to see both sides of the diagnoal, one is sufficient. The diagnoal itself also doesn't have any information (each variable is correlated perfectly with itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seaborn theme to use\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# adapt the part of the matrix that is shown\n",
    "mask = np.zeros_like(correlation_matrix, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "# sns.palplot(sns.diverging_palette(240, 0)) Uncomment to try out different color palettes to use below\n",
    "cmap = sns.diverging_palette(240, 0, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(correlation_matrix, mask=mask, cmap=cmap, vmax=0.15,vmin=-0.15,  # vmax and vmin define the upper and lower boundaries of the colormap respectively\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can put the above code into a function to make use of it more flexibly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(correlation_matrix):\n",
    "    # Set the seaborn theme to use\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # adapt the part of the matrix that is shown\n",
    "    mask = np.zeros_like(correlation_matrix, dtype=bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    # sns.palplot(sns.diverging_palette(240, 0)) Uncomment to try out different color palettes to use below\n",
    "    cmap = sns.diverging_palette(240, 0, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(correlation_matrix, mask=mask, cmap=cmap, vmax=0.15,vmin=-0.15,  # vmax and vmin define the upper and lower boundaries of the colormap respectively\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(df.corr(method='pearson', min_periods=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Linear regression in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an [ordinarly least squares, or OLS regression - usually simply \"linear regression\"](https://www.encyclopedia.com/social-sciences/applied-and-social-sciences-magazines/ordinary-least-squares-regression), we try to understand the *simultaenous* effect of multiple independent variables (X), on our dependet variable (y). As an example, we want to see how education and age, together, influence an employee's salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustrative purposes, we start with a single independent variable (age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[['age']],df[['salary']],color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have used here the matplotlib function for graphing, rather than Seaborn. As for many things in Python, there are many different packages that serve the same functions with certain differences. Matplotlib is good for drawing graphs in a basic format and in interfacing with different data types. Seaborn has more of a design functionality: it can do very high-quality color schemes etc.\n",
    "\n",
    "We now move onto the regression part. Again, there are many packages that enable us to do this. We present two here: the `statsmodels` package and the `scikit` library.\n",
    "1. Pros of `statsmodels` package: great summary of the regression, easier to do polynomial regression and plotting \n",
    "2. Pros of `scikit` library: very easy to do machine learning concepts on it. \n",
    "\n",
    "We will see how to do linear regression in both. For this part of the class, we use `statsmodels` (note that `statsmodels` has already been imported above to run hypothesis tests). For machine learning concepts that we will see later, we will use `scikit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['age']]\n",
    "Y = df[['salary']]\n",
    "\n",
    "X = sm.add_constant(X) # In this package, by default, the regression will have no intercept, hence we need to manually add it to the X matrix, and call the result X_sm\n",
    "lm = sm.OLS(Y, X).fit() # Fit an OLS with vector Y as dependent and matrix X_sm as independent\n",
    "print(lm.summary()) # Display the summary of model results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that often, it makes sense to standardize the data first. We will look at this in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import abline_plot\n",
    "\n",
    "ax = df.plot(x=\"age\", y=\"salary\", kind='scatter', color=\"blue\")\n",
    "abline_plot(model_results=lm, ax=ax, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at multivariate associations, by adding in education as a second explanatory variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "zdata = df[['salary']]\n",
    "ydata = df[['age']]\n",
    "xdata = df[['education']]\n",
    "ax.scatter3D(xdata, ydata, zdata, c=zdata)\n",
    "ax.set_xlabel('Education')\n",
    "ax.set_ylabel('Age')\n",
    "ax.set_zlabel('Salary')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1eUHrHwAbzr"
   },
   "source": [
    "We can run an OLS just like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uwwb1mdZVtZK"
   },
   "outputs": [],
   "source": [
    "X = df[['age','education']]\n",
    "Y = df[['salary']]\n",
    "X = sm.add_constant(X)\n",
    "lm = sm.OLS(Y, X).fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkOWrTquCXDo"
   },
   "source": [
    "Let's get a better look at the data, visualizing the coefficients. The below code displays the confidence intervals of each coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rcemx_37CJu4"
   },
   "outputs": [],
   "source": [
    "err_series = lm.params - lm.conf_int(alpha=0.05)[0]\n",
    "coef_df = pd.DataFrame({'coef': lm.params.values[1:],\n",
    "                        'err': err_series.values[1:],\n",
    "                        'varname': err_series.index.values[1:]\n",
    "                       })\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "coef_df.plot(x='varname', y='coef', kind='bar', \n",
    "             ax=ax, color='none', \n",
    "             yerr='err', legend=False)\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel('')\n",
    "ax.scatter(x=pd.np.arange(coef_df.shape[0]), \n",
    "           marker='o', s=120, \n",
    "           y=coef_df['coef'], color='black')\n",
    "ax.axhline(y=0, linestyle='-', color='red', linewidth=4)\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ckRgYXLHBDKd"
   },
   "source": [
    "What we actually care about is, whether employees exit the company. Hence, y should indicate whether an employee is an exiteer (not to be confused with a [Brexiteer](https://en.wikipedia.org/wiki/Glossary_of_Brexit_terms)). We combine all available information, in order to try to explain why someone left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "63NVojyXBg6m"
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'exit']\n",
    "Y = df[[\"exit\"]]\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHmDqmj0CLbR"
   },
   "source": [
    "We are now ready to fit our OLS model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O7eF3BWUCQxx"
   },
   "outputs": [],
   "source": [
    "lm = sm.OLS(Y,X).fit()\n",
    "print (lm.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9F-SoRqCSpo"
   },
   "source": [
    "Let's get a better look at the coefficients. To do so, we will first create a new function based on the code we previously saw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coef(model):\n",
    "    err_series = model.params - model.conf_int(alpha=0.05)[0]\n",
    "    coef_df = pd.DataFrame({'coef': model.params.values[1:],\n",
    "                            'err': err_series.values[1:],\n",
    "                            'varname': err_series.index.values[1:]\n",
    "                           })\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    coef_df.plot(x='varname', y='coef', kind='bar', \n",
    "                 ax=ax, color='none', \n",
    "                 yerr='err', legend=False)\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "    ax.scatter(x=pd.np.arange(coef_df.shape[0]), \n",
    "               marker='o', s=120, \n",
    "               y=coef_df['coef'], color='black')\n",
    "    ax.axhline(y=0, linestyle='-', color='red', linewidth=4)\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxlK-nQtCXEZ"
   },
   "outputs": [],
   "source": [
    "plot_coef(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Logistic regression in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our model were correct, how would an employee behave that has the same attributes as Employee No. 1, but a `boss_survey` value of `-1`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = X.iloc[[0]]\n",
    "example.at[0, 'boss_survey'] = -1\n",
    "lm.predict(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's unclear how to interpret the result of 1.15. It's certainly not a probability! This is where Logistic regression comes in:\n",
    "\n",
    "In a [Logistic (or Logit) regression](https://en.wikipedia.org/wiki/Logistic_regression), we try to understand the *simultaenous* effect of multiple independent variables (X), on our dependet variable (y), when y is either 0 or 1, exactly as in our problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2NyfS9NVtZN"
   },
   "outputs": [],
   "source": [
    "logm = sm.Logit(endog=Y, exog=X).fit()\n",
    "print (logm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tUXVJwWeJS5l"
   },
   "source": [
    "We can, again, use our custom-made visualization function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QXPwUP3xHpq7"
   },
   "outputs": [],
   "source": [
    "plot_coef(logm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UpF5DvCJSCF5"
   },
   "source": [
    "For further reading on Logit, see, for example, [here](https://statisticalhorizons.com/whats-so-special-about-logit). For more on Logit in Python, see [here](https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "T1.0_ORG2.0_Org20_Tutorial1.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "dfbf29d6b298ee06653be85b1336aa59e8cd7929544b69296d5ef5d391694a35"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('smm750': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
