{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897d6a28",
   "metadata": {},
   "source": [
    "# 1. Automatically scrape job postings of a competitor\n",
    "\n",
    "We will now see scraping in action. Imagine you are working in HR for a major retailer. Your boss asks you to monitor the strategic hiring decisions of your close competitors. Naturally, you cannot go and call them up - but you could take a look at their job postings to see ($i$) how much they are hiring, ($ii$) what types of positions they are hiring for.\n",
    "\n",
    "Now, you could log onto their website every day, see what job postings there are, compare that with the job postings from before, and save the relevant data. But why go through so much effort if we can just automate the task?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da075fd",
   "metadata": {},
   "source": [
    "## 1.1 A simple case - using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8fb50f",
   "metadata": {},
   "source": [
    "The first example relies purely on what we have learned about BeautifulSoup and Requests (and a bit of Pandas!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ba464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bd6bf4",
   "metadata": {},
   "source": [
    "We are searching for positions in the head office of Aldi. On the website, we see that there are different types of head office positions, each with their own website. Let's get the links to those sub-sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.aldirecruitment.co.uk/head-office\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f146c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for link in soup.findAll('a'):\n",
    "    links.append(link.get('href'))\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4cfbfd",
   "metadata": {},
   "source": [
    "We want to get only the links to actual job postings, so we have to clean the results somewhat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.aldirecruitment.co.uk/head-office\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "links = []\n",
    "for link in soup.findAll('a'):\n",
    "    new_link = link.get('href')\n",
    "    if new_link != None and new_link.startswith('/head-office/'):\n",
    "        links.append(new_link)\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa80de",
   "metadata": {},
   "source": [
    "As we use \"../head-office\" as our base url, we do not need to repeat it. Accordingly, we make a few final adjustments to the link collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.aldirecruitment.co.uk/head-office\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "links = []\n",
    "for link in soup.findAll('a'):\n",
    "    new_link = link.get('href')\n",
    "    if new_link != None and new_link.startswith('/head-office/'):\n",
    "        new_link = new_link.replace('/head-office','')\n",
    "        if new_link != '/':\n",
    "            links.append(new_link)\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd72effa",
   "metadata": {},
   "source": [
    "Let's see how many postings there are on one of the sub-sites. For this, we have to find the right tags, using their class argument. Again, inspecting the site is very important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2014535",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_url = url + links[0]\n",
    "page = requests.get(category_url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "postings = soup.findAll(\"div\", class_=\"c-career--dropdown\")\n",
    "len(postings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c6b051",
   "metadata": {},
   "source": [
    "We now extract some information from the actual position: the job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a40a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = postings[0].find(\"div\", class_=\"c-career--dropdown__content\").find('h2')\n",
    "print(title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a5bb9e",
   "metadata": {},
   "source": [
    "Aside from the title and the text description (which we will ignore in this example, but which can hold extremely useful information), there are some key details about the job, such as the work time and the salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6210c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "details = postings[0].findAll(\"div\", class_=\"c-job-details__content\")\n",
    "print(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce29c5f7",
   "metadata": {},
   "source": [
    "We definitely want to get the salary information. Sometime, the text gives multiple values, so let's make sure to save the lowest and the highest value (of course, multiple values may be due to changes over time or for different starting requirements - we can adapt our scraper to capture arbitrary complexity later on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c550ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail = details[0]\n",
    "detail_text = detail.find('div', class_=\"c-job-details__text\").text\n",
    "print(detail_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = detail_text.replace(',','')\n",
    "temp = temp.replace('-','')\n",
    "temp = temp.split()\n",
    "salary_numbers = [float(s[1:]) for s in temp if s.startswith('£')]\n",
    "ub = max(salary_numbers)\n",
    "lb = min(salary_numbers)\n",
    "print(ub)\n",
    "print(lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01972c7",
   "metadata": {},
   "source": [
    "Let's also try to capture the weekly working hours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0469241",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail = details[2]\n",
    "detail_text = detail.find('div', class_=\"c-job-details__text\").text\n",
    "for s in detail_text.split():\n",
    "    if '-hour' in s:\n",
    "        work_time = s\n",
    "        work_time = int(work_time.replace('-hour',''))\n",
    "print(work_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6438d9",
   "metadata": {},
   "source": [
    "The following code combines our extraction of job details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "details = postings[0].findAll(\"div\", class_=\"c-job-details__content\")\n",
    "for detail in details:\n",
    "    detail_title = detail.find('span', class_=\"c-job-details__title\").text\n",
    "    detail_text = detail.find('div', class_=\"c-job-details__text\").text\n",
    "    if detail_title == 'Salary':\n",
    "        temp = detail_text.replace(',','')\n",
    "        temp = temp.replace('-','')\n",
    "        temp = temp.split()\n",
    "        salary_numbers = [float(s[1:]) for s in temp if s.startswith('£')]\n",
    "        ub = max(salary_numbers)\n",
    "        lb = min(salary_numbers)\n",
    "    elif detail_title == 'Hours and benefits':\n",
    "        for s in detail_text.split():\n",
    "            if '-hour' in s:\n",
    "                work_time = s\n",
    "                work_time = int(work_time.replace('-hour',''))\n",
    "print(ub)\n",
    "print(lb)\n",
    "print(work_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069e2dd",
   "metadata": {},
   "source": [
    "Finally, we are putting it all together into a simple-to-call function that returns a data frame of job postings. We have to make a few adjustments to avoid errors. These are marked with comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_aldi_jobs(starting_page = 'head-office'):\n",
    "    url = \"https://www.aldirecruitment.co.uk/\" + starting_page\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    links = []\n",
    "    for link in soup.findAll('a'):\n",
    "        new_link = link.get('href')\n",
    "        if new_link != None and new_link.startswith('/head-office/'):\n",
    "            new_link = new_link.replace('/head-office','')\n",
    "            if new_link != '/':\n",
    "                links.append(new_link)\n",
    "    \n",
    "    department = []\n",
    "    titles = []\n",
    "    ubs = []\n",
    "    lbs = []\n",
    "    hours = []\n",
    "    for link in links:\n",
    "        category_url = url + link\n",
    "        page = requests.get(category_url)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        postings = soup.findAll(\"div\", class_=\"c-career--dropdown\")\n",
    "        for posting in postings:\n",
    "            ## Also grabbing the department information\n",
    "            dep_name = link.replace('-',' ').replace('/','')\n",
    "            department.append(dep_name)\n",
    "            titles.append(posting.find(\"div\", class_=\"c-career--dropdown__content\").find('h2').text)\n",
    "            details = posting.findAll(\"div\", class_=\"c-job-details__content\")\n",
    "            for detail in details:\n",
    "                detail_title = detail.find('span', class_=\"c-job-details__title\").text\n",
    "                detail_text = detail.find('div', class_=\"c-job-details__text\").text\n",
    "                if detail_title == 'Salary':\n",
    "                    temp = detail_text.replace(',','')\n",
    "                    temp = temp.replace('-','')\n",
    "                    temp = temp.split()\n",
    "                    salary_numbers = [float(s[1:]) for s in temp if s.startswith('£')]\n",
    "                    ## Salary may not be specified\n",
    "                    if len(salary_numbers) > 0:\n",
    "                        ## Salaries are sometimes specified as per week instead of per year\n",
    "                        if 'per' in temp and 'week' in temp:\n",
    "                            salary_numbers = [salary*52 for salary in salary_numbers]\n",
    "                        ubs.append(max(salary_numbers))\n",
    "                        lbs.append(min(salary_numbers))\n",
    "                    else:\n",
    "                        ubs.append(None)\n",
    "                        lbs.append(None)\n",
    "                ## Some postings say \"Benefits\" instead of \"Hours and benefits\", and sometimes the spelling is capitalized differently\n",
    "                elif detail_title.lower() == 'hours and benefits' or detail_title.lower() == 'benefits':\n",
    "                    ## Some postings do not specify a number of hours per week\n",
    "                    work_time = None\n",
    "                    for s in detail_text.split():\n",
    "                        if '-hour' in s:\n",
    "                            work_time = s\n",
    "                            ## Some postings write, e.g., 40-hour per week, some 40-hours per week\n",
    "                            if '-hours' in s:\n",
    "                                work_time = int(work_time.replace('-hours',''))\n",
    "                            else:\n",
    "                                work_time = int(work_time.replace('-hour',''))\n",
    "                    hours.append(work_time)\n",
    "                        \n",
    "    job_data = pd.DataFrame(\n",
    "        {'Department': department,\n",
    "         'Job title': titles,\n",
    "         'Salary lower': lbs,\n",
    "         'Salary upper': ubs,\n",
    "         'Weekly hours': hours\n",
    "        })\n",
    "    return job_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0bb58",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a24b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "aldi_job_data = scrape_aldi_jobs()\n",
    "aldi_job_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b86b79",
   "metadata": {},
   "source": [
    "We can now explore the data frame, improve our code if we find issues, and then analyze it. For example, let's have a look at a simple histogram of postings per department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aee99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(30, 10)\n",
    "sns.histplot(data=aldi_job_data, x=\"Department\",ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1fc1d9",
   "metadata": {},
   "source": [
    "Finally, save the job postings we found as a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce7d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aldi_job_data.to_csv('Aldi_postings_2021-10-14.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499a8ef",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Can you correct the scraping function to avoid issues with the salary or weekly hour number? Define a new function `scrape_aldi_jobs_corrected`, in which you eliminate any issues you come across in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5253d806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60311b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69ae57a2",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "The idea is that we run our code regularly and observe the current postings. For this, we need to do the following:\n",
    "1. Load an existing csv file with job postings (on Moodle)\n",
    "2. For any job currently found on the website, check whether it was already posted previously (for simplicity, only compare Department and Job title)\n",
    "3. If the job posting is new, add today as the posting date in the data frame. Otherwise, add the date of the previous file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4dd466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a551dc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04e19a87",
   "metadata": {},
   "source": [
    "## 1.2 A more advanced case - using Selenium to enter details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a406a1",
   "metadata": {},
   "source": [
    "Let's get data from a second competitor. We will use Lidle here (I am, of course, not biased in my choices). Check out Lidl's hiring page https://careers.lidl.co.uk/ and start a search. Then look at the link where you landed at - can you see why things are a bit more complex here?\n",
    "\n",
    "Since we cannot just find the right links, we need to act like a browser. This is where Selenium comes in - it will literally run a browser!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cdaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2c8c8",
   "metadata": {},
   "source": [
    "We need to choose the type of browser that Selenium runs - and each comes with its own access and installation requirements. I personally recommend using Chrome. However, to use Chrome, with Selenium, you need to install ChromeDriver. The site https://sites.google.com/chromium.org/driver/downloads gives download files, which should work fine for Windows users. Simply download and unpack the Zip, which gives you a .exe file. Either move it somewhere on your PATH, or add it to your path (https://stackoverflow.com/questions/4822400/register-an-exe-so-you-can-run-it-from-any-command-line-in-windows gives a good description how to).\n",
    "\n",
    "On Mac, you may run into access issues. The easiest way to proceed is to use Homebrew (https://brew.sh/ shows how to use it). Once done, type\n",
    "```\n",
    "brew install chromedriver\n",
    "```\n",
    "into your terminal.\n",
    "Other options can be found here: https://www.kenst.com/2015/03/installing-chromedriver-on-mac-osx/ (note that the syntax can be a bit outdated).\n",
    "\n",
    "Once done, the below code will open a new window in the browser of your choice (here Chrome):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e74df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://careers.lidl.co.uk/jobsearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0817a32",
   "metadata": {},
   "source": [
    "You will notice that this is a completely new Chrome process - so cookies are not yet accepted. To see what's going on, let's start by accepting cookies. How do we do this? We simply find the right button (by insepcting the site, then copying the XPath), and then let Selenium click this button!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fcafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie_button = driver.find_element_by_xpath('//*[@id=\"CybotCookiebotDialog\"]/div/div[1]/button')\n",
    "cookie_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d597d6b3",
   "metadata": {},
   "source": [
    "The Lidl jobs site offers the option to select head office positions, just like Aldi. However, the link is relatively complex, so we will simply let Selenium click on the right button again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_office_button = driver.find_element_by_xpath('//*[@id=\"react-container\"]/div[3]/div/div/div/div/div[1]/div/a')\n",
    "head_office_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e12b04d",
   "metadata": {},
   "source": [
    "There are a few positions here. If you click on any of those, you'll notice that the links are relatively simple in structure and don't depend on your website interaction. Hence, the easiest is for us to collect all the posting links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "posting_urls = []\n",
    "postings = driver.find_elements_by_class_name('jobResult')\n",
    "for posting in postings:\n",
    "    posting_urls.append(posting.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da6af5",
   "metadata": {},
   "source": [
    "It may be that postings are spread across multiple pages (delete the filters to see this). Luckily, there is a forward button that let's us scroll through the pages. We can easily combine this with our previous code. Note that we only move forward if the next page element actually exists.\n",
    "There can be a problem with identifying the button location. Usually, this can be fixed by maximizing the window in which Selenium runs.\n",
    "\n",
    "\n",
    "Also, we add an implict wait so that the server has time to respond before our clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7818e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = False\n",
    "posting_urls = []\n",
    "while not stop:\n",
    "    driver.implicitly_wait(5)\n",
    "    postings = driver.find_elements_by_class_name('jobResult')\n",
    "    print(\"Found \" + str(len(postings)) + \" postings\")\n",
    "    for posting in postings:\n",
    "        posting_urls.append(posting.get_attribute('href'))\n",
    "    next_elements = driver.find_elements_by_class_name('paginationArrow_next')\n",
    "    if len(next_elements) > 0:\n",
    "        element = driver.find_element_by_class_name('paginationArrow_next')\n",
    "        if element.is_enabled():\n",
    "            driver.execute_script(\"arguments[0].click();\", element)\n",
    "            time.sleep(3)\n",
    "        else:\n",
    "            stop = True\n",
    "    else:\n",
    "        stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67abf1e8",
   "metadata": {},
   "source": [
    "## Exercise 3 - we will get back to this one during the tutorial\n",
    "\n",
    "Now that we have loaded the urls of the relevant vacancies, can you extract some key information (e.g., title and postcode of location)? This will be similar to what we did for the Aldi vacancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b532f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739db3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c420cc1",
   "metadata": {},
   "source": [
    "# 2. Basics of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7511eab2",
   "metadata": {},
   "source": [
    "Let's start by defining the class `Car`. No matter the car, it will have a make, a model, a number of horsepowers, and a (maximum) speed. So we can use these attributes to define objects of our class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cfde5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car():\n",
    "    def __init__(self,make, model, hp, speed):\n",
    "        self.make = make\n",
    "        self.model = model\n",
    "        self.hp = hp\n",
    "        self.speed = speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a4e79",
   "metadata": {},
   "source": [
    "We can now define an object, for example, a Toyota Camry with 100 horse power and a maximum speed of 120 (miles/hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a990f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "car1 = Car(\"Toyota\",\"Camry\",100,120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1aed0b",
   "metadata": {},
   "source": [
    "When coding, we often print out \"things\", at the very least to debug. Let's see what happens when we print out our object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff77d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(car1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0a31f",
   "metadata": {},
   "source": [
    "To adjust how an object is represented as a string, we (re)define the `__str__` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ccc88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car():\n",
    "    def __init__(self,make, model, hp, speed):\n",
    "        self.make = make\n",
    "        self.model = model\n",
    "        self.hp = hp\n",
    "        self.speed = speed\n",
    "    def __str__(self):\n",
    "        return \"Make: \" + self.make + \", Model: \" + self.model + \", Horse Power: \" + str(self.hp) + \", Speed: \" + str(self.speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf909e8",
   "metadata": {},
   "source": [
    "Now we should get something more descriptive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd0112",
   "metadata": {},
   "outputs": [],
   "source": [
    "car2 = Car(\"Toyota\",\"Camry\",100,120)\n",
    "print(car2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d12c6",
   "metadata": {},
   "source": [
    "Note that a string method *should* be unique to the specific object. If we have two `Car` objects that are different, they should also return a different string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb3707e",
   "metadata": {},
   "source": [
    "We can also access the attributes of our `Car` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(car2.speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3949cb",
   "metadata": {},
   "source": [
    "And, since we can access the attributes, we can also set them to different values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e032ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "car2.speed = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dd09ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(car2.speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c656c0",
   "metadata": {},
   "source": [
    "However, you should not change objects like this (because you may be changing things that the developer of the class doesn't want you to change, so that the code can continue running smoothly). Commonly, if you can safely change an object's attribute, there will be a \"setter\" method to do so. In this method, the developer may add in some safety checks to ensure your change is valid. Also, you should be using \"getter\" methods to call up attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49cebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car():\n",
    "    def __init__(self,make, model, hp, speed):\n",
    "        self.make = make\n",
    "        self.model = model\n",
    "        self.hp = hp\n",
    "        self.speed = speed\n",
    "    def __str__(self):\n",
    "        return \"Make: \" + self.make + \", Model: \" + self.model + \", Horse Power: \" + str(self.hp) + \", Speed: \" + str(self.speed)\n",
    "    def set_speed(self,speed):\n",
    "        if speed > 0:\n",
    "            self.speed = speed\n",
    "        else:\n",
    "            print(\"invalid speed\")\n",
    "    def get_speed(self):\n",
    "        return self.speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6f39dc",
   "metadata": {},
   "source": [
    "Let's create another car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b497b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "car3 = Car(\"Toyota\",\"Camry\",100,120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff7c304",
   "metadata": {},
   "source": [
    "Now, try to set the speed to something invalid: this will not work (rightly so!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf04be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car3.set_speed(-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f56219",
   "metadata": {},
   "source": [
    "We can confirm that nothing changed, by either calling the attribute directly (not recommended), or calling the \"getter\" method (recommended):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de2ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "car3.get_speed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f9e88",
   "metadata": {},
   "source": [
    "By directly accessing the `speed` attribute, however, we can set it to something invalid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f20eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "car3.speed = -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f31c573",
   "metadata": {},
   "source": [
    "In fact, the maximum speed is now negative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(car3.get_speed())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98dbd7",
   "metadata": {},
   "source": [
    "Let's correct this - with the \"setter\" method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05570a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car3.set_speed(130)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a13fab",
   "metadata": {},
   "source": [
    "Finally, we check again, using the \"getter\" method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24db9472",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(car3.get_speed())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9e9cbb",
   "metadata": {},
   "source": [
    "We can also use our objects as input to a method. For example, let's see whether our `Car` object is fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6932225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_car_fast(car):\n",
    "    if car.get_speed() > 130:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deebc1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(is_car_fast(car3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07f426",
   "metadata": {},
   "source": [
    "An important part of object-oriented programming is the ability to inherit. For example, just as we can make `Car` objects, we can make `Ford` objects. But any `Ford` is also a `Car`! In Python, inheritance is marked by adding another class as parameter to the class we are programming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c5157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ford(Car):\n",
    "    def __init__(self, model, hp, speed):\n",
    "        Car.__init__(self, \"Ford\", model, hp, speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fbe071",
   "metadata": {},
   "source": [
    "In our case above, when we create a `Ford`, we create a `Car` with `\"Ford\"` as the make. Le'ts try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "ford1 = Ford(\"Focus\",80,110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b11df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ford1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ford1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be07a4a",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a630de",
   "metadata": {},
   "source": [
    "Define a class `Person`, as follows:\n",
    "1. define an `__init__` method that takes a name and an age as argument and set the corresponding object-attributes\n",
    "2. define a `get_name` method that returns the name of the `Person`-object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434cb89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "357045fc",
   "metadata": {},
   "source": [
    "Next, define a class `Organization`:\n",
    "1. the class should have an `__init__` method, in which an empty object-specific list `hires` gets created\n",
    "2. the class should also have a `hire` method that takes a `Person` as an input and adds the person to the list of hires\n",
    "3. finally, the class should have a `__str__` method that returns a string including all the names of the hires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eae085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dc67ac7",
   "metadata": {},
   "source": [
    "Create two persons with name and age. Then, create an organization, hire the two person, and run `print` on the organization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f1e310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62ab8cf7",
   "metadata": {},
   "source": [
    "# 3. Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42220db",
   "metadata": {},
   "source": [
    "We now turn to `scrapy`. As always, there is a package to import (and install, if you haven't done so already):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b46c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a1e54",
   "metadata": {},
   "source": [
    "We create a spider (which inherits from the `scrapy.Spider`), which starts with two subpages of http://quotes.toscrape.com/. Every time our spider parses a webpage, it simply saves the entire HTML document locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f61643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    start_urls = [\n",
    "        'http://quotes.toscrape.com/page/1/',\n",
    "        'http://quotes.toscrape.com/page/2/',\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f'quotes-page{page}.html'\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)\n",
    "        self.log(f'Saved file {filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500fca7",
   "metadata": {},
   "source": [
    "Usually, we run spiders from the terminal (we will see how to do this later). However, we can run the spider from a Jupyter notebook - once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48bfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "process = CrawlerProcess()\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c39cd4",
   "metadata": {},
   "source": [
    "But try doing this again (without restarting the kernel), and you are likely to run into problems. There are, in principle, ways around this, but they are quite tedious. So let's take a look at running `scrapy` from the terminal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtvc_env",
   "language": "python",
   "name": "dtvc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
