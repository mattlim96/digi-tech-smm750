{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ffa4b72",
   "metadata": {},
   "source": [
    "# Social Media APIs and Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e39491",
   "metadata": {},
   "source": [
    "## 1. Measuring engagement with Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289fd0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pytrends.request import TrendReq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a4e4dc",
   "metadata": {},
   "source": [
    "Let's use our newfound skills with the Google trends API to measure enagagement following a marketing campaign. The company Red Bull spends a large sum of money on its Formula 1 team, in order to market its brand. But it also does lots of other marketing activities. Because most people don't go to the supermarket to buy a Red Bull drink after watching a Formula 1 event, it can be quite tricky to associate sales with different marketing campaigns. But social media allows us to capture consumer reactions and engagement in real time! So if we know that consumer engagement leads to more sales (at least, on the long term), it can be extremely valuable to measure engagement following marketing campaigns.\n",
    "\n",
    "Our question will be twofold:\n",
    "1. Does Red Bull create engagement with its Formula 1 expenditures?\n",
    "2. Does the Pilot matter? I.e., is engagement related to success?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a36b2",
   "metadata": {},
   "source": [
    "### 1.1: Querying the interest over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91744533",
   "metadata": {},
   "source": [
    "We start by pulling Google trends data for the search term \"red bull\" between March and yesterday (the Formula 1 season started at the end of March). We also convert our dataframe and ensure the date column is actually seen as a date by `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad42a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytrend = TrendReq()\n",
    "pytrend.build_payload(kw_list = [\"red bull\"],timeframe='2021-03-01 2021-11-01')\n",
    "trends = pytrend.interest_over_time()\n",
    "trendsdf = pd.DataFrame(data = {'date': trends.index.tolist(),\n",
    "                                'search': trends[\"red bull\"].tolist()})\n",
    "trendsdf['date'] = pd.to_datetime(trendsdf['date'])\n",
    "trendsdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f969313",
   "metadata": {},
   "source": [
    "Next, we take a look at the daily search hits (recall that the maximum will always be 100 in any Google Trends query):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84c372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot( x = 'date',\n",
    "             y = 'search',\n",
    "             data = trendsdf,\n",
    "             label = 'daily hits', color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3944fd4c",
   "metadata": {},
   "source": [
    "### 1.2: Combining it with race data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb7cd6",
   "metadata": {},
   "source": [
    "We have some data on the searches. Now, we can add race data into the mix, but we need to make sure that the dates are actual dates again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "racingdf = pd.read_csv('red_bull_race_results.csv')\n",
    "racingdf['date'] = pd.to_datetime(racingdf['date'], format=\"%d.%m.%y\")\n",
    "racingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d311c1",
   "metadata": {},
   "source": [
    "The dataset gives the positioning of the two Red Bull pilots, Sergio Pérez and Max Verstappen. A missing value indicates that the pilot did not finish the race."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f62d7d3",
   "metadata": {},
   "source": [
    "Similar to before, we can merge the two data frames by date, in order to understand whether race day implies a high number of searches. For simplicity, we can take only one extra column of `racingdf`, to see whether the date exists or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(trendsdf, racingdf[['date','perez']], how='left',on='date')\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9114132",
   "metadata": {},
   "source": [
    "Whereever there is a missing value in the `perez` column, there was no race on the day. We can adjust our dataframe accordingly and plot our merged result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c66c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['raceday'] = temp['perez'].notna()\n",
    "sns.scatterplot( x = 'date',\n",
    "             y = 'search',\n",
    "             data = temp,\n",
    "            hue=\"raceday\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4192d",
   "metadata": {},
   "source": [
    "A first look at the data seems to indicate that there is support for the hypothesis that the Formula 1 marketing leads to customer engagement. Of course, more work is needed to establish robust evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857074d3",
   "metadata": {},
   "source": [
    "### 1.3: Measuring the importance of the pilot\n",
    "\n",
    "We will turn to the second question instead (whether the pilots matter). For this, we need to first clean the racing dataset.\n",
    "\n",
    "Since disqualification is often a topic of intense interest in Formula 1, we create an additional column to measure whether a driver has not completed the race.\n",
    "\n",
    "There is one special case, which requires contextual knowledge: on 2021-06-06, Verstappen did not finish the race and was only placed because he had completed more than 90%. For consistency, we may consider putting a 1 in the column `'verstappen_out'` here (this is a typical case in which you want to check for consistency).\n",
    "\n",
    "We then remove the `NAs` by replacing them with the worst result (this is of course just one possible choice and requires further analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7a751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "racingdf['perez_out'] = racingdf['perez'].isna().astype(int)\n",
    "racingdf['verstappen_out'] = racingdf['verstappen'].isna().astype(int)\n",
    "racingdf.loc[racingdf['date'] == '2021-06-06','verstappen_out'] = 1\n",
    "racingdf['perez'] = racingdf['perez'].fillna(racingdf['perez'].max())\n",
    "racingdf['verstappen'] = racingdf['verstappen'].fillna(racingdf['verstappen'].max())\n",
    "racingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf40080",
   "metadata": {},
   "source": [
    "Next, we want to find out the engagement around the race days. We create an `\"engagement\"` column in our `racingdf`. In particular, we go through all the race dates and find the engagement (race day searches relative to average search number in the week - this is our very own definition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda31304",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_engagement = []\n",
    "for i in range(len(racingdf)):\n",
    "    race_date = racingdf.iloc[i,]['date']\n",
    "    trendsdf['difftime'] = trendsdf['date']-race_date\n",
    "    trendsdf['difftime'] = [diff.days for diff in trendsdf['difftime']]\n",
    "    racetrends = trendsdf[abs(trendsdf['difftime']) <= 3]\n",
    "    if len(racetrends[racetrends['difftime']==0]) > 0:\n",
    "        relative_engagement.append( racetrends[racetrends['difftime']==0].iloc[0]['search']/np.mean(racetrends['search']) )\n",
    "    else:\n",
    "        relative_engagement.append(np.nan)\n",
    "racingdf['engagement'] = relative_engagement\n",
    "racingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc718dd7",
   "metadata": {},
   "source": [
    "Now that we have the data, we can try to see what effects the placements have on engagement. Of course, we also analyze the effect of a driver not finishing the race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ee555",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = racingdf.drop(['date', 'engagement'], axis=1)\n",
    "Y = racingdf.engagement\n",
    "X = sm.add_constant(X)\n",
    "lm = sm.OLS(Y,X).fit()\n",
    "print (lm.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286272e1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe260c",
   "metadata": {},
   "source": [
    "## 2. Using Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653de47",
   "metadata": {},
   "source": [
    "It might be useful to also see what users are tweeting about regarding the races. Let's take a look at the Twitter API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f922d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc7a828",
   "metadata": {},
   "source": [
    "With the Twitter API we can access most of Twitter’s functionality from within Python (that means both reading **and** writing Tweets, or finding out about users and trends). The package of choice is *Tweepy*, which deals with all the messy details.\n",
    "\n",
    "To access the Twitter API, you need to be authenticated. Hence, every request has to come with authentication information. To get this information in the first place, we need to generate our own credentials with a Developer Account:\n",
    "\n",
    "1. Go to the <a href=https://developer.twitter.com/en>Twitter Developer Site</a> and apply for a Developer Account (you will need a Twitter account for this).\n",
    "2. Create an application (e.g., \"My_first_application\"). Credentials and limits are per application, not per account.\n",
    "3. Once you have created your application, you can transfer your consumer API key and secret, as well as your app access key and secret to the Python code below (see also https://developer.twitter.com/en/docs/basics/authentication/overview/oauth)\n",
    "\n",
    "You can directly add your data as a string like this:\n",
    "```\n",
    "CONSUMER_API_KEY = 'COPY STRING HERE'\n",
    "CONSUMER_API_SECRET = 'COPY STRING HERE'\n",
    "ACCESS_KEY = 'COPY STRING HERE'\n",
    "ACCESS_SECRET = 'COPY STRING HERE'\n",
    "```\n",
    "\n",
    "So that I can share my code without everyone using my credentials (which would probably lead to me being blocked by Twitter), I'm instead reading the data from a csv here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_access = pd.read_csv('API_access.csv',delimiter=';')\n",
    "CONSUMER_API_KEY = api_access[api_access['api'] == 'twitter_consumer_api_key']['key'].tolist()[0]\n",
    "CONSUMER_API_SECRET = api_access[api_access['api'] == 'twitter_consumer_api_secret']['key'].tolist()[0]\n",
    "ACCESS_KEY = api_access[api_access['api'] == 'twitter_access_key']['key'].tolist()[0]\n",
    "ACCESS_SECRET = api_access[api_access['api'] == 'twitter_access_secret']['key'].tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b868c",
   "metadata": {},
   "source": [
    "We are also not allowed to request too many Tweets at the same time. There are per-day limits, as well as \"rate limits\" for 15-minute blocks. If you exceed your limits, you **will** get blocked for some time. For detailed information on the limits, check out https://developer.twitter.com/en/docs/twitter-api/v1/tweets/timelines/overview and https://developer.twitter.com/en/docs/rate-limits.\n",
    "In many cases, we can use the functionality of Tweepy to automatically delay calls in order to wait on the rate limit - but be aware that this doesn't always work, and we may need to manually add timeouts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fb87e1",
   "metadata": {},
   "source": [
    "We are now ready to create our verified interface (automatically waiting on our rate limit as necessary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_API_KEY, CONSUMER_API_SECRET)\n",
    "auth.set_access_token(ACCESS_KEY, ACCESS_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1060fbf9",
   "metadata": {},
   "source": [
    "Let's download some tweets! Note that the API only allows you to download tweets based on general queries from the past 9 days. If you want to download older tweets, you will need to dowload the tweets of a particular account (see below). For simplicity, we will focus on the last week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85644ef",
   "metadata": {},
   "source": [
    "### 2.1: Pulling all tweets based on a search query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5644f",
   "metadata": {},
   "source": [
    "Let's search for tweets with the hash tag `\"#redbull\"`. You can find details about the tweet objects at https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.search,q=\"#redbull\",lang=\"en\").items(5):\n",
    "    print(\"Created at: \" + str(tweet.created_at))\n",
    "    print(\"User: \" + tweet.user.screen_name)\n",
    "    print(\"Followers: \" + str(tweet.user.followers_count))\n",
    "    print(\"Content: \" + tweet.text)\n",
    "    print(\"---------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aa041c",
   "metadata": {},
   "source": [
    "When requesting tweets in this manner, the API will cut anything beyond 140 characters. That means, even if we search for tweets with #redbull, the tweet we receive may not contain the hashtag. However, we can add the parameter `tweet_mode='extended'` to our `tweepy.Cursor()` call. In this case, returned tweets no longer have a `.text` attribute, but a `.full_text` attribute\n",
    "\n",
    "(alternatively, we can \"hydrate\" tweets at any time, using just their ID (i.e. request the full text). You can thus use only the tweet ID to share your data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144eedfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.search,q=\"#redbull\",lang=\"en\", tweet_mode='extended').items(5):\n",
    "    print(\"Created at: \" + str(tweet.created_at))\n",
    "    print(\"User: \" + tweet.user.screen_name)\n",
    "    print(\"Followers: \" + str(tweet.user.followers_count))\n",
    "    print(\"Content: \" + tweet.full_text) # Note: when looking at extended tweets, there is no attribute `.text`\n",
    "    print(\"---------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa16a3",
   "metadata": {},
   "source": [
    "We can extend this, to get all tweets of the last week. Note: in principle, the `include_rts=False` option should exclude any retweets. In practice, however, there seems to be some issues in how `tweepy` performs this exclusion. Hence, we make sure manually to only capture original tweets, using the keyworkd `\"-filter:retweets\"` in our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9759cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_day = datetime.utcnow() - timedelta(days=7)\n",
    "tweets = []\n",
    "for tweet in tweepy.Cursor(api.search,q=\"#redbull -filter:retweets\",\n",
    "                           lang=\"en\",since=str(start_day.date())).items():\n",
    "    tweets.append(tweet)\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f4a6d",
   "metadata": {},
   "source": [
    "Let's start having a look at Tweeter demographics. Where are tweeters from (we only consider accounts with locations)? Remember, that the <a href=\"https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet\">Developer Platform</a> has all the relevant information about tweet objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe633f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweets[0]\n",
    "tweet.user.location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b74444",
   "metadata": {},
   "source": [
    "We will consider only locations that have at least 5 tweets emerging from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6795c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_loc = [tweet.user.location for tweet in tweets if tweet.user.location != \"\"]\n",
    "tweet_loc_df = pd.DataFrame(tweet_loc,columns=['location'])\n",
    "tweet_loc_df = tweet_loc_df.groupby('location')['location'].count().reset_index(name='count')\n",
    "tweet_loc_df = tweet_loc_df[tweet_loc_df['count'] >= 5]\n",
    "tweet_loc_df.sort_values(by='count',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eece30",
   "metadata": {},
   "source": [
    "Let's now take a look at when the Tweets where sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d9a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweets[0]\n",
    "tweet.created_at.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.created_at.date().day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed57dc",
   "metadata": {},
   "source": [
    "We can collect the counts per day into a table and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a30377",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_day = [tweet.created_at.date().day for tweet in tweets]\n",
    "tweet_day_df = pd.DataFrame(tweet_day,columns=['day'])\n",
    "tweet_day_df = tweet_day_df.groupby('day')['day'].count().reset_index(name='count')\n",
    "sns.lineplot(y=tweet_day_df['count'], x = tweet_day_df['day'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170750b0",
   "metadata": {},
   "source": [
    "Finally, we explore the other hashtags within the tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweets[1]\n",
    "tweet.entities['hashtags']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaaf19e",
   "metadata": {},
   "source": [
    "There might be multiple hashtags of course, each one is its own dictionary, within a list of dictionaries. In each dictionary, the key `'text'` gives the hashtag and the key `'indices'` gives the position within the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945cf763",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.entities['hashtags'][1]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d806e377",
   "metadata": {},
   "source": [
    "Let's now get all the hashtags from our tweets (except the redbull hashtags). We can convert these into a dataframe, where we count the occurences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attached_tags = [tweet.entities['hashtags'] for tweet in tweets if tweet.entities['hashtags'] != []]\n",
    "attached_tags_cleaned = [hashtag['text'].lower() for tags in attached_tags for hashtag in tags if hashtag['text'].lower() != 'redbull']\n",
    "hashtag_df = pd.DataFrame(attached_tags_cleaned,columns=['hashtag'])\n",
    "hashtag_df = hashtag_df.groupby('hashtag')['hashtag'].count().reset_index(name='count')\n",
    "hashtag_df.sort_values(by='count',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7629491",
   "metadata": {},
   "source": [
    "### 2.2: Finding followers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e122e951",
   "metadata": {},
   "source": [
    "We now want to learn more about the people (and company accounts) that follow Red Bull (as well as about whom they follow other than Red Bull). Let's start with finding some of Red Bull's followers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd70d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_rb = []\n",
    "for follower in tweepy.Cursor(api.followers,\"redbull\").items(5):\n",
    "    followers_rb.append(follower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef84be9",
   "metadata": {},
   "source": [
    "A company like Red Bull has quite some followers and we would run into problems trying to get all at once. But if you really care about collecting everything, the following code times out for 15 minutes after every 3000 names (watch out, this would still run for about 170 hours. It is advisable to check the code in more detail and to add an option for saving lists once in a while):\n",
    "\n",
    "```\n",
    "followers_rb = []\n",
    "users = tweepy.Cursor(api.followers, screen_name=accountvar, count=200).items()\n",
    "while True:\n",
    "    try:\n",
    "        user = next(users)\n",
    "    except tweepy.TweepError:\n",
    "        time.sleep(60*15)\n",
    "        user = next(users)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    followers_rb.append(user.screen_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e213d0a7",
   "metadata": {},
   "source": [
    "Note that followers are saved as \"User\" objects, with their very own attributes, found here: https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user. The twitter-handle is defined by the `screen_name` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d0a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "follower = followers_rb[0]\n",
    "follower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "follower = followers_rb[1]\n",
    "follower.screen_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6615a1e",
   "metadata": {},
   "source": [
    "Can we get other accounts that this person follows? (Twitter defines those as friends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933083c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in tweepy.Cursor(api.friends, screen_name=follower.screen_name).items(10):\n",
    "    print(user.screen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0b8b46",
   "metadata": {},
   "source": [
    "Sometimes, the information is set to private, so we don't know who the person is following. Hence, we need to do some Exception management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9489e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for user in tweepy.Cursor(api.friends, screen_name=follower.screen_name).items(10):\n",
    "        print(user.screen_name)\n",
    "except tweepy.TweepError:\n",
    "    print(\"Follower \" + follower.screen_name + \" does not provide access to their friends.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b0630",
   "metadata": {},
   "source": [
    "Let's combine this for multiple of Red Bull's followers. For the first 5 followers, let's get up 10 of the accounts that they follow each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b22221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_followers_friends = []\n",
    "for follower in followers_rb:\n",
    "    followers_friends = []\n",
    "    try:\n",
    "        for user in tweepy.Cursor(api.friends, screen_name=follower.screen_name).items(10):\n",
    "            followers_friends.append(user)\n",
    "    except tweepy.TweepError:\n",
    "        print(\"Follower \" + follower.screen_name + \" does not provide access to their friends.\")\n",
    "    print(\"Added \" + str(len(followers_friends)) + \" friends of follower \" + follower.screen_name)\n",
    "    all_followers_friends += followers_friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for followers_friend in all_followers_friends:\n",
    "    print(followers_friend.screen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5b9a8",
   "metadata": {},
   "source": [
    "It's easy to imagine how we could create a network of accounts, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca6197",
   "metadata": {},
   "source": [
    "### 2.3: Finding a specific user's tweets (over time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d931a88",
   "metadata": {},
   "source": [
    "We can also take a look at all the Tweets of a specific account. When looking at an account's Tweets, we do not have to worry about date limits (but there are still restrictions, so let's make sure not to pull too many).\n",
    "\n",
    "To search an account's Tweets, we can use either the `.screen_name` or the `.id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = all_followers_friends[0]\n",
    "user_screen_name = user.screen_name\n",
    "user_id = user.id\n",
    "print(user_screen_name)\n",
    "print(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02285e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.user_timeline,id=user_id).items(5):\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1c604c",
   "metadata": {},
   "source": [
    "In a similar manner, we can get the tweets of Red Bull (by `.id` or `.screen_name`)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_rb = []\n",
    "for tweet in tweepy.Cursor(api.user_timeline,screen_name='redbull').items(100):\n",
    "    tweets_rb.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets_rb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1758a92a",
   "metadata": {},
   "source": [
    "### 2.4: Back to our engagement measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6086d3",
   "metadata": {},
   "source": [
    "Let's try to enrich our `racingdf` using Tweet data.\n",
    "\n",
    "We can only collect tweets by hashtag for a bit more than a week. Hence, I have prepared a full week of tweets every Wednesday after a Formula 1 race in the last few weeks. This is stored as a `pickle` file - a system that allows to directly save arbitrary Python objects outside of our program. Hence, once we call up the pickle file, we get back exactly the variables we saved into it. Since I saved a list of tweets, the return value from `pickle.load(file)` will be a list of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ac547",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Tweets_210908_211027.txt', 'rb') as file:\n",
    "    tweets = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fe8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b60ac4",
   "metadata": {},
   "source": [
    "Briefly recall our dataset `racingdf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d32344",
   "metadata": {},
   "outputs": [],
   "source": [
    "racingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eee0be5",
   "metadata": {},
   "source": [
    "The tweet data only captures the last four races, so we will focus on the dates of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "racedates = racingdf.tail(4)['date'].tolist()\n",
    "racedates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88353224",
   "metadata": {},
   "source": [
    "Let's take the first of these race dates, as well as an \"arbitrary\" tweet and compare dates (don't be surprised, this will lead to an error!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b6c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "racedate = racedates[0]\n",
    "tweet = tweets[219]\n",
    "tweet.created_at.date() - racedate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f1ab8",
   "metadata": {},
   "source": [
    "The problem here is that the date objects used by `tweepy` are not the same as the date objects used by `pandas`! Hence, let's convert the tweet's date with `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(tweet.created_at.date()) - racedate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee63384",
   "metadata": {},
   "source": [
    "We can convert this time difference into days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbceed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.to_datetime(tweet.created_at.date()) - racedate).days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2624f3",
   "metadata": {},
   "source": [
    "Ok, the tweet comes from the right day. Let's take a look what it is about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed3f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[219].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8365831",
   "metadata": {},
   "source": [
    "The name \"Verstappen\" appears in here. We can, of course, check this automatically with Python (note that we use `.lower()` to avoid issues when comparing different capitalization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df05ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "'verstappen' in tweets[219].text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69642c4e",
   "metadata": {},
   "source": [
    "We can combine the above code to create two new columns: a count of tweets talking about Perez and a count of tweets talking about Verstappen. We first create an empty column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "racingdf['tweets_perez'] = 0\n",
    "racingdf['tweets_verstappen'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50efcd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for racedate in racedates:\n",
    "    perez_count = 0\n",
    "    verstappen_count = 0\n",
    "    for tweet in tweets:\n",
    "        if (pd.to_datetime(tweet.created_at.date()) - racedate).days in [0,1]:\n",
    "            if 'perez' in tweet.text.lower():\n",
    "                perez_count += 1\n",
    "            if 'verstappen' in tweet.text.lower():\n",
    "                verstappen_count += 1\n",
    "    racingdf.loc[racingdf['date'] == racedate,\"tweets_perez\"] = perez_count\n",
    "    racingdf.loc[racingdf['date'] == racedate,\"tweets_verstappen\"] = verstappen_count\n",
    "racingdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2001fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = racingdf.tail(4)\n",
    "ax = sns.scatterplot(x=reduced_df.date, y=reduced_df.perez, color = \"red\")\n",
    "ax.set_ylabel(\"perez placement\",color=\"red\",fontsize=14)\n",
    "ax2 = plt.twinx()\n",
    "sns.scatterplot(x=reduced_df.date, y=reduced_df.tweets_perez, color = \"blue\")\n",
    "ax2.set_ylabel(\"perez tweets\",color=\"blue\",fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab955ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = racingdf.tail(4)\n",
    "ax = sns.scatterplot(x=reduced_df.date, y=reduced_df.verstappen, color = \"red\")\n",
    "ax.set_ylabel(\"verstappen placement\",color=\"red\",fontsize=14)\n",
    "ax2 = plt.twinx()\n",
    "sns.scatterplot(x=reduced_df.date, y=reduced_df.tweets_verstappen, color = \"blue\")\n",
    "ax2.set_ylabel(\"verstappen tweets\",color=\"blue\",fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d6d091",
   "metadata": {},
   "source": [
    "### Discussion point: Can you interpret these results? Why is the number of mentions of Verstappen so high on September 12?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db0b00",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### 2.5 (Exercise): Finding out more about the people talking about Verstappen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04194b36",
   "metadata": {},
   "source": [
    "**Finding the right tweets and users**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbbde70",
   "metadata": {},
   "source": [
    "Start by finding all the tweets in which the word `'verstappen'` appears, making sure to eliminate any capitalizaiton issues. Put those tweets into a list `verstappen_tweets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c0b6b",
   "metadata": {},
   "source": [
    "Next, find out how many tweets each user made that made any of the `verstappen_tweets`.\n",
    "\n",
    "One possibile approach is to create a dictionary of tweet-lists, loop through the tweets, and change the dictionary as follows: if the `.user.screen_name` attribute has not appeared before, create a new entry into the dictionary. The attribute is the key and as a value, create a new list with the current tweet inside. If the `.user.screen_name` attribute has appeared before, simply append the current tweet to the corresponding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095da5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e8d690",
   "metadata": {},
   "source": [
    "Next, create a list of `active_tweeters` and a list of `inactive_tweeters`. The former list should contain the users with more than one tweet within `verstappen_tweets`.\n",
    "\n",
    "Note: it will be useful later on if you store the `.user`-objects, not just the `.user.screen_name` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496c9087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07d80d",
   "metadata": {},
   "source": [
    "How many `active_tweeters` are there? How many `inactive_tweeters`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6beb31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "256155bf",
   "metadata": {},
   "source": [
    "**Counting followers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a07d8",
   "metadata": {},
   "source": [
    "Next, we will take a look at the followers of our different tweeters. For the active (resp. inactive) tweeters, display a histogram showing the number of followers. The relevant user-attribute is `.followers_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc82bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c302e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320eb167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0672daf4",
   "metadata": {},
   "source": [
    "The extremely skewed nature of the number of followers makes it difficult to see anything or make comparisons. When we have heavily skewed data, we usually use the logarithm instead. Hence, repeat the plotting exercise with the `np.log()` of the `.followers_count`. Keep in mind that some may have 0 followers, so add a 1 to avoid errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ebed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f20f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff2247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dc3f222",
   "metadata": {},
   "source": [
    "Do you see any differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc65743d",
   "metadata": {},
   "source": [
    "**Analyzing highly influential followers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eae4b8",
   "metadata": {},
   "source": [
    "Next, we will take a look at the `active_tweeters` with more than $10,000$ followers. Create a new list, `selected_accounts`, and store the relevant user-objects within the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f42685",
   "metadata": {},
   "source": [
    "To understand the type of highly influential followers better, we take a look at the tweets of the `selected_accounts`. In particular, we explore the hashtags that they use.\n",
    "\n",
    "1. Create a list of hashtags\n",
    "2. loop through the `selected_accounts`\n",
    "3. For each user, find the last 100 (complete) tweets they wrote (using `tweepy.Cursor(api.user_timeline,screen_name=user.screen_name, tweet_mode='extended').items(100)` )\n",
    "4. Within each tweet, collect the list of hashtags (using `.entities['hashtags']`) and append these to our overall list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab19d5e",
   "metadata": {},
   "source": [
    "If you print out the list of hashtags, you'll see that each hashtag is a dictionary with two keys:\n",
    "1. `'text'`: this gives the actual hashtag\n",
    "2. `'indices'`: this gives the position of the hashtag within the tweet\n",
    "\n",
    "Go through the list of hashtags and store only the actual hashtag using key `'text'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4dbc6",
   "metadata": {},
   "source": [
    "Finally, add the hashtags into a dictionary, together with the number of times they appear (using the function `.groupby()` of your newly created data frame). Sort the dataframe by the occurence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038f75c",
   "metadata": {},
   "source": [
    "What types of influential accounts do you think actively post about Red Bull?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a9f382",
   "metadata": {},
   "source": [
    "Similar to hashtags, we can also find out which users are being mentioned in tweets (the @'s). Repeat the above search, but instead of searching for hashtags, search for the users mentioned with `.entities['user_mentions']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64481ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b439d87",
   "metadata": {},
   "source": [
    "The `user_mentions` is another dictionary. This time, it contains the `screen_name` of the mentioned user, the `name` (display name), the `id`, an `id_str` (same as `id` but saved as a string instead of a number), and the `indices` which indicate the position of the mention within the tweet. Go through the list of mentions and pick out the display name (`name`) for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd22846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d03d533f",
   "metadata": {},
   "source": [
    "As before, create a data frame with a count for how often each mention appears, and display the data frame sorted by count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467839cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtvc_env",
   "language": "python",
   "name": "dtvc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
